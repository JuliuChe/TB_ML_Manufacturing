{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee428bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:44:39.819966Z",
     "iopub.status.busy": "2025-02-26T09:44:39.819764Z",
     "iopub.status.idle": "2025-02-26T09:44:39.826232Z",
     "shell.execute_reply": "2025-02-26T09:44:39.825619Z"
    },
    "papermill": {
     "duration": 0.015495,
     "end_time": "2025-02-26T09:44:39.827768",
     "exception": false,
     "start_time": "2025-02-26T09:44:39.812273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PJRT_DEVICE'] = 'TPU'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deac1fe6",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-26T09:44:39.840407Z",
     "iopub.status.busy": "2025-02-26T09:44:39.840214Z",
     "iopub.status.idle": "2025-02-26T09:45:01.109178Z",
     "shell.execute_reply": "2025-02-26T09:45:01.108317Z"
    },
    "papermill": {
     "duration": 21.277291,
     "end_time": "2025-02-26T09:45:01.110916",
     "exception": false,
     "start_time": "2025-02-26T09:44:39.833625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/test_Npy_fold_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/train_Npy_fold_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/train_Npy_fold_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/train_Npy_fold_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/test_Npy_fold_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/test_Npy_fold_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/train_Npy_fold_0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/test_Npy_fold_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/test_Npy_fold_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mynumpyfiles/NumpyDS/train_Npy_fold_3"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import csv\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf326d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:45:01.126015Z",
     "iopub.status.busy": "2025-02-26T09:45:01.125619Z",
     "iopub.status.idle": "2025-02-26T09:46:06.524633Z",
     "shell.execute_reply": "2025-02-26T09:46:06.522443Z"
    },
    "papermill": {
     "duration": 65.408324,
     "end_time": "2025-02-26T09:46:06.526090",
     "exception": false,
     "start_time": "2025-02-26T09:45:01.117766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/site-packages (23.0.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\r\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r",
      "\u001B[2K     \u001B[91m━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.6/1.8 MB\u001B[0m \u001B[31m17.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━\u001B[0m \u001B[32m1.7/1.8 MB\u001B[0m \u001B[31m25.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.8/1.8 MB\u001B[0m \u001B[31m19.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 23.0.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Uninstalling pip-23.0.1:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled pip-23.0.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed pip-25.0.1\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.18.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-2.18.0:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully uninstalled tensorflow-2.18.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-cpu\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (2.1.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (25.1.24)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (24.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (5.29.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (75.8.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (1.17.2)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (1.70.0)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (3.8.0)\r\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (2.0.2)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (3.12.1)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (0.4.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/site-packages (from tensorflow-cpu) (0.37.1)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-cpu) (0.45.1)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow-cpu) (0.14.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow-cpu) (2025.1.31)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow-cpu) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-cpu) (3.0.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow-cpu) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow-cpu) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-cpu) (0.1.2)\r\n",
      "Downloading tensorflow_cpu-2.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (230.0 MB)\r\n",
      "\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/230.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.7/230.0 MB\u001B[0m \u001B[31m54.3 MB/s\u001B[0m eta \u001B[36m0:00:05\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.6/230.0 MB\u001B[0m \u001B[31m117.9 MB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.8/230.0 MB\u001B[0m \u001B[31m160.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m127.1/230.0 MB\u001B[0m \u001B[31m163.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━\u001B[0m \u001B[32m159.6/230.0 MB\u001B[0m \u001B[31m162.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━\u001B[0m \u001B[32m192.9/230.0 MB\u001B[0m \u001B[31m172.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[32m204.7/230.0 MB\u001B[0m \u001B[31m147.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m229.9/230.0 MB\u001B[0m \u001B[31m154.0 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m230.0/230.0 MB\u001B[0m \u001B[31m59.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: tensorflow-cpu\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed tensorflow-cpu-2.18.0\r\n",
      "\u001B[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip uninstall -y tensorflow && pip install tensorflow-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3db18d6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:06.549120Z",
     "iopub.status.busy": "2025-02-26T09:46:06.548703Z",
     "iopub.status.idle": "2025-02-26T09:46:40.529363Z",
     "shell.execute_reply": "2025-02-26T09:46:40.528253Z"
    },
    "papermill": {
     "duration": 33.995979,
     "end_time": "2025-02-26T09:46:40.532466",
     "exception": false,
     "start_time": "2025-02-26T09:46:06.536487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "import torch_xla.runtime as xr\n",
    "\n",
    "from torch_xla.distributed.parallel_loader import MpDeviceLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec59e338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:40.569629Z",
     "iopub.status.busy": "2025-02-26T09:46:40.569142Z",
     "iopub.status.idle": "2025-02-26T09:46:40.649637Z",
     "shell.execute_reply": "2025-02-26T09:46:40.648783Z"
    },
    "papermill": {
     "duration": 0.101814,
     "end_time": "2025-02-26T09:46:40.652022",
     "exception": false,
     "start_time": "2025-02-26T09:46:40.550208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "myMeta=\"/kaggle/input/mynumpyfiles/NumpyDS/GlobalFoldsFiles_Train_Test_Augmented_Cleaned.csv\"\n",
    "myGlobalDs=pd.read_csv(myMeta)\n",
    "myGlobalDs.drop(myGlobalDs.columns[myGlobalDs.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
    "myGlobalDs[\"FilePath\"] = [fpath.replace(\"\\\\\", \"/\") for fpath in myGlobalDs[\"FilePath\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ce6fc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:40.680632Z",
     "iopub.status.busy": "2025-02-26T09:46:40.680314Z",
     "iopub.status.idle": "2025-02-26T09:46:40.703182Z",
     "shell.execute_reply": "2025-02-26T09:46:40.701990Z"
    },
    "papermill": {
     "duration": 0.04024,
     "end_time": "2025-02-26T09:46:40.704773",
     "exception": false,
     "start_time": "2025-02-26T09:46:40.664533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Type</th>\n",
       "      <th>nb</th>\n",
       "      <th>Label</th>\n",
       "      <th>condLabel</th>\n",
       "      <th>FileName</th>\n",
       "      <th>FilePath</th>\n",
       "      <th>LabelIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10_T02 M06 (VHM 309-12)</td>\n",
       "      <td>VHM</td>\n",
       "      <td>0006_label_T02 M06 (VHM 309-12).npy</td>\n",
       "      <td>test_Npy_fold_0/0006_label_T02 M06 (VHM 309-12...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10_T02 M06 (VHM 309-12)</td>\n",
       "      <td>VHM</td>\n",
       "      <td>0022_label_T02 M06 (VHM 309-12).npy</td>\n",
       "      <td>test_Npy_fold_0/0022_label_T02 M06 (VHM 309-12...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>27.0</td>\n",
       "      <td>10_T02 M06 (VHM 309-12)</td>\n",
       "      <td>VHM</td>\n",
       "      <td>0028_label_T02 M06 (VHM 309-12).npy</td>\n",
       "      <td>test_Npy_fold_0/0028_label_T02 M06 (VHM 309-12...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>29.0</td>\n",
       "      <td>10_T02 M06 (VHM 309-12)</td>\n",
       "      <td>VHM</td>\n",
       "      <td>0030_label_T02 M06 (VHM 309-12).npy</td>\n",
       "      <td>test_Npy_fold_0/0030_label_T02 M06 (VHM 309-12...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Test</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10_T02 M06 (VHM 309-12)</td>\n",
       "      <td>VHM</td>\n",
       "      <td>0034_label_T02 M06 (VHM 309-12).npy</td>\n",
       "      <td>test_Npy_fold_0/0034_label_T02 M06 (VHM 309-12...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold  Type    nb                    Label condLabel  \\\n",
       "0     0  Test   5.0  10_T02 M06 (VHM 309-12)       VHM   \n",
       "1     0  Test  21.0  10_T02 M06 (VHM 309-12)       VHM   \n",
       "2     0  Test  27.0  10_T02 M06 (VHM 309-12)       VHM   \n",
       "3     0  Test  29.0  10_T02 M06 (VHM 309-12)       VHM   \n",
       "4     0  Test  33.0  10_T02 M06 (VHM 309-12)       VHM   \n",
       "\n",
       "                              FileName  \\\n",
       "0  0006_label_T02 M06 (VHM 309-12).npy   \n",
       "1  0022_label_T02 M06 (VHM 309-12).npy   \n",
       "2  0028_label_T02 M06 (VHM 309-12).npy   \n",
       "3  0030_label_T02 M06 (VHM 309-12).npy   \n",
       "4  0034_label_T02 M06 (VHM 309-12).npy   \n",
       "\n",
       "                                            FilePath  LabelIDs  \n",
       "0  test_Npy_fold_0/0006_label_T02 M06 (VHM 309-12...         0  \n",
       "1  test_Npy_fold_0/0022_label_T02 M06 (VHM 309-12...         0  \n",
       "2  test_Npy_fold_0/0028_label_T02 M06 (VHM 309-12...         0  \n",
       "3  test_Npy_fold_0/0030_label_T02 M06 (VHM 309-12...         0  \n",
       "4  test_Npy_fold_0/0034_label_T02 M06 (VHM 309-12...         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGlobalDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729488ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:40.723991Z",
     "iopub.status.busy": "2025-02-26T09:46:40.723754Z",
     "iopub.status.idle": "2025-02-26T09:46:40.737973Z",
     "shell.execute_reply": "2025-02-26T09:46:40.737126Z"
    },
    "papermill": {
     "duration": 0.026073,
     "end_time": "2025-02-26T09:46:40.739778",
     "exception": false,
     "start_time": "2025-02-26T09:46:40.713705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>nb</th>\n",
       "      <th>LabelIDs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11780.000000</td>\n",
       "      <td>7215.000000</td>\n",
       "      <td>11780.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>991.312266</td>\n",
       "      <td>4.573005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.414274</td>\n",
       "      <td>533.009652</td>\n",
       "      <td>3.262599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>515.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1010.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1477.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1837.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Fold           nb      LabelIDs\n",
       "count  11780.000000  7215.000000  11780.000000\n",
       "mean       2.000000   991.312266      4.573005\n",
       "std        1.414274   533.009652      3.262599\n",
       "min        0.000000     5.000000      0.000000\n",
       "25%        1.000000   515.000000      2.000000\n",
       "50%        2.000000  1010.000000      5.000000\n",
       "75%        3.000000  1477.000000      7.000000\n",
       "max        4.000000  1837.000000     10.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGlobalDs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a205ea85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:40.759316Z",
     "iopub.status.busy": "2025-02-26T09:46:40.759096Z",
     "iopub.status.idle": "2025-02-26T09:46:44.743294Z",
     "shell.execute_reply": "2025-02-26T09:46:44.741966Z"
    },
    "papermill": {
     "duration": 3.996925,
     "end_time": "2025-02-26T09:46:44.745499",
     "exception": false,
     "start_time": "2025-02-26T09:46:40.748574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "\n",
    "import math, random\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class DataUtils():\n",
    "    #---------------------------------------------\n",
    "    #Load a file and returns it as a list\n",
    "    #---------------------------------------------\n",
    "    @staticmethod\n",
    "    def x_loading(subsetXTrainFiles, myDir):\n",
    "        #Takes a list of files and returns a numpy array of shape (nObservations, nChannels, nSamples)\n",
    "        X_subset=[]\n",
    "        \n",
    "        for file in subsetXTrainFiles:    \n",
    "            myArray=np.load(os.path.join(myDir, file))\n",
    "            X_subset.append(myArray)\n",
    "        X_subset=np.array(X_subset) #X_subset.shape (1989 observations, 4 channels :sound, accel X,Y,Z, 250062 samples per observation)\n",
    "        \n",
    "        return X_subset\n",
    "    \n",
    "    @staticmethod\n",
    "    def saveFile(myNpy, destDir, fileName):\n",
    "        \"\"\"Save a file.\"\"\"\n",
    "        np.save(os.path.join(destDir, fileName), myNpy)\n",
    "\n",
    "    #---------------------------------------------\n",
    "    #Align the data to have a fixed duration.\n",
    "    #---------------------------------------------\n",
    "    @staticmethod\n",
    "    def padTruncate(mySig, maxTime, fs):\n",
    "        \"\"\"Pad or truncate the data to have a fixed duration.\n",
    "        Args:\n",
    "            mySig: the signal as a list\n",
    "            maxTime: The maximum time in milliseconds.\n",
    "            fs: the sampling rate in Hz    \n",
    "            \"\"\"\n",
    "        sLen = mySig.shape[0]\n",
    "        trunc=0\n",
    "        maxLen=int(maxTime*int(fs/1000))\n",
    "        if sLen > maxLen:\n",
    "            trunc=1\n",
    "            mySig = mySig[:, :maxLen]\n",
    "        elif sLen < maxLen:\n",
    "            trunc=-1\n",
    "            mySig = np.pad(mySig, ((0, int(maxLen - sLen)),(0,0)), mode='wrap')\n",
    "        \n",
    "        return (trunc, len(mySig), mySig)\n",
    "    \n",
    "    def addGaussianNoise(mySig, std=0.02):\n",
    "        \"\"\"Add a gaussian noise.\"\"\"\n",
    "        mySig_float=mySig.astype(np.float32)\n",
    "        noise = np.random.normal(0, std*np.std(np.abs(mySig_float), axis=0), mySig.shape)\n",
    "        noisySig=np.clip(mySig_float+noise, -32768,32767)        \n",
    "        return noisySig.astype(np.int16)\n",
    "    \n",
    "    def timeShift(mySig, shift_lim=0.5):\n",
    "        \"\"\"Shifts the data in time (reintroduce ending values at the beginning.\"\"\"\n",
    "        _, sLen = mySig.shape\n",
    "        shiftAmt = int(np.random.random() * shift_lim * sLen)\n",
    "        return np.roll(mySig, shiftAmt, axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def augment_fft(data, factor=1.2):\n",
    "        \"\"\"Augmente ou diminue certaines fréquences du signal\"\"\"\n",
    "        \n",
    "        fft_data = np.fft.fft(data, axis=0)\n",
    "        fft_data = fft_data * factor  # Modification du spectre\n",
    "        newData=np.real(np.fft.ifft(fft_data, axis=0))  # Retourne le signal temporel\n",
    "        newData = np.clip(newData, -32768, 32767)\n",
    "        return newData.astype(np.int16)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Generate a Mel Spectrogram Excellent for Audio Data\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def mel_spectro_gram(mySig, n_mels=64, n_fft=1024, hop_len=None, fs=50000):\n",
    "        if hop_len is None:\n",
    "            hop_len = n_fft // 4\n",
    "            \n",
    "        top_db = 80\n",
    "        mySig=mySig.astype(np.float32)\n",
    "        mySigTensor=torch.from_numpy(mySig.T)\n",
    "        # spec has shape [channel, n_mels, time], where channel is mono, stereo etc\n",
    "        spec = transforms.MelSpectrogram(fs, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(mySigTensor)\n",
    "        # Convert to decibels\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        spec = spec.unsqueeze(0) if spec.dim() == 2 else spec\n",
    "        return (spec, hop_len)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Generate a \"classic\" Spectrogram for Accelerometer Data\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def spectro_gram(mySig, n_fft=1024, hop_len=None, fs=50000):\n",
    "        if hop_len is None:\n",
    "            hop_len = n_fft // 4\n",
    "            \n",
    "        mySig=mySig.astype(np.float32)\n",
    "        mySigTensor=torch.from_numpy(mySig.T)\n",
    "        # spec has shape [channel, n_mels, time], where channel is sound, accel X, accel Y, accel Z \n",
    "        spec = transforms.Spectrogram(n_fft=n_fft, hop_length=hop_len, power=2)(mySigTensor)\n",
    "        # Convert to decibels\n",
    "        spec = transforms.AmplitudeToDB()(spec)\n",
    "        spec = spec.unsqueeze(0) if spec.dim() == 2 else spec\n",
    "        return (spec, hop_len)\n",
    "    \n",
    "    # ----------------------------\n",
    "    # Visualize a Spectrogram\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def show_spectrogram(spec, fs=50000, hop=256, title=\"Spectrogram\", ylabel='Mel Frequency Bands', channels=['Sound', 'AccX', 'AccY', 'AccZ'], mel=False):\n",
    "        nbChannels=spec.shape[0]\n",
    "        fig, axs = plt.subplots(nbChannels, 1, figsize=(18, 12))\n",
    "        if nbChannels==1:\n",
    "            axs=[axs]\n",
    "        timeAxis=np.arange(0, spec.shape[2]*hop, hop)/fs\n",
    "        freqAxis = np.linspace(0, fs / 2, spec.shape[1])\n",
    "        for i in range(nbChannels):\n",
    "            if mel:\n",
    "                img=axs[i].imshow(spec[i].detach().numpy(), aspect='auto', origin='lower', cmap='viridis', extent=[timeAxis[0], timeAxis[-1], 0, spec[i].shape[0]])\n",
    "            else:\n",
    "                img=axs[i].imshow(spec[i].detach().numpy(), aspect='auto', origin='lower', cmap='viridis', extent=[timeAxis[0], timeAxis[-1], freqAxis[0], freqAxis[-1]])\n",
    "                \n",
    "            axs[i].set_title(f\"Channel {channels[i]}\")\n",
    "            axs[i].set_ylabel(ylabel)\n",
    "        plt.xlabel('Time [s]')\n",
    "        plt.suptitle(title)\n",
    "        plt.colorbar(img, ax=axs, orientation='vertical')\n",
    "        plt.show()\n",
    "        \n",
    "    # ----------------------------\n",
    "    # Augment a Spectrogram\n",
    "    # ----------------------------\n",
    "    @staticmethod\n",
    "    def spectro_Augment(spectro, maxMaskPercentage=0.1,nFreqMask=1, nTimeMasks=1):\n",
    "        \"\"\"Augmente ou diminue certaines fréquences du signal\"\"\"\n",
    "        nChannel, nFreq, nSteps = spectro.shape\n",
    "        mask_value=spectro.mean()\n",
    "        aug_spec=spectro.clone()\n",
    "        freqMaskParam=maxMaskPercentage*nFreq\n",
    "        timeMaskParam=maxMaskPercentage*nSteps\n",
    "        \n",
    "        for ch in range(nChannel):\n",
    "            channelSpec=aug_spec[ch]\n",
    "            for _ in range(nFreqMask):\n",
    "                channelSpec=transforms.FrequencyMasking(freqMaskParam)(channelSpec, mask_value)\n",
    "\n",
    "            for _ in range(nTimeMasks):\n",
    "                channelSpec=transforms.TimeMasking(timeMaskParam)(channelSpec, mask_value)\n",
    "            aug_spec[ch]=channelSpec\n",
    "            \n",
    "        return aug_spec\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f75b73f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:44.766910Z",
     "iopub.status.busy": "2025-02-26T09:46:44.766374Z",
     "iopub.status.idle": "2025-02-26T09:46:44.774266Z",
     "shell.execute_reply": "2025-02-26T09:46:44.773078Z"
    },
    "papermill": {
     "duration": 0.020925,
     "end_time": "2025-02-26T09:46:44.775880",
     "exception": false,
     "start_time": "2025-02-26T09:46:44.754955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "#With TPU\n",
    "from torch_xla.distributed.parallel_loader import MpDeviceLoader\n",
    "\n",
    "\n",
    "#Creation of a custom Dataset for PyTorch\n",
    "\n",
    "#df must contain Label and filepath only for one fold of training data. Folds will be dealt with externally to the DataLoader class.\n",
    "\n",
    "#Datapath is the path to the folder containing all the folds (i.e. F:\\Data_BachelorHES\\DataSet_CNC\\DataSetsFolds) \n",
    "\n",
    "class DataDS(Dataset):\n",
    "    \n",
    "    def __init__(self, df, datapath):\n",
    "        self.df=df\n",
    "        self.datapath=str(datapath)\n",
    "        self.duration=5001.24\n",
    "        self.fs=50000\n",
    "        self.channel=4\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row=self.df.iloc[idx]\n",
    "        dirFile=os.path.join(self.datapath,row['FilePath'])\n",
    "        observationLoad=np.load(dirFile)\n",
    "        labelId=row['LabelIDs']\n",
    "        _, lenObs, obs=DataUtils.padTruncate(observationLoad, self.duration, self.fs)\n",
    "        spec, _ = DataUtils.spectro_gram(obs, n_fft=1024, hop_len=None, fs=self.fs)\n",
    "        augspec=DataUtils.spectro_Augment(spec, maxMaskPercentage=0.1,nFreqMask=2, nTimeMasks=2)\n",
    "        return (augspec, labelId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e81b8c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:44.798052Z",
     "iopub.status.busy": "2025-02-26T09:46:44.797698Z",
     "iopub.status.idle": "2025-02-26T09:46:44.810928Z",
     "shell.execute_reply": "2025-02-26T09:46:44.809859Z"
    },
    "papermill": {
     "duration": 0.026534,
     "end_time": "2025-02-26T09:46:44.812701",
     "exception": false,
     "start_time": "2025-02-26T09:46:44.786167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "#       Spectrogram   |  Shape  (nbChannel, nbFreq, nbTime)|  DataType \n",
    "#Augmented Spec shape |        torch.Size([4, 513, 977])   |  torch.FloatTensor\n",
    "\n",
    "# ----------------------------\n",
    "# Audio Classification Model\n",
    "# ----------------------------\n",
    "class ToolClassifier (nn.Module):\n",
    "    # ----------------------------\n",
    "    # Build the model architecture\n",
    "    # ----------------------------\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        #torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        #This convolution block \n",
    "        inChannels=4\n",
    "        outChannels=16\n",
    "        self.conv1 = nn.Conv2d(inChannels, outChannels, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(outChannels)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "\n",
    "        # Second Convolution Block\n",
    "        inChannels=16\n",
    "        outChannels=32\n",
    "        self.conv2 = nn.Conv2d(inChannels, outChannels, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(outChannels)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "\n",
    "        # Third Convolution Block\n",
    "        inChannels=32\n",
    "        outChannels=64\n",
    "        self.conv3 = nn.Conv2d(inChannels, outChannels, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(outChannels)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Fourth Convolution Block\n",
    "        inChannels=64\n",
    "        outChannels=128\n",
    "        self.conv4 = nn.Conv2d(inChannels, outChannels, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(outChannels)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=outChannels, out_features=11)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "    # ----------------------------\n",
    "    # Forward pass computations\n",
    "    # ----------------------------\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Final output\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c5d377a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:44.833935Z",
     "iopub.status.busy": "2025-02-26T09:46:44.833685Z",
     "iopub.status.idle": "2025-02-26T09:46:44.847413Z",
     "shell.execute_reply": "2025-02-26T09:46:44.846133Z"
    },
    "papermill": {
     "duration": 0.02651,
     "end_time": "2025-02-26T09:46:44.849148",
     "exception": false,
     "start_time": "2025-02-26T09:46:44.822638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Training Loop\n",
    "# ----------------------------\n",
    "def normalize_ds(dataloader, device):\n",
    "    #Compute mean and standard deviation accross all train data\n",
    "    # results are mean and std for every spectrogram accross all channels (here mean and std have size (4,513,977))\n",
    "    sumInp=None\n",
    "    sumSqDiff=None\n",
    "    totObs=0\n",
    "    \n",
    "    #iterate over data to calculate global data mean\n",
    "    for i, data in enumerate(dataloader): \n",
    "        \n",
    "        inputs =data[0].to(device)\n",
    "        if sumInp is None:\n",
    "            sumInp=torch.zeros(inputs.size(1),inputs.size(2),inputs.size(3), device=device)\n",
    "            sumSqDiff=torch.zeros(inputs.size(1),inputs.size(2),inputs.size(3), device=device)\n",
    "            \n",
    "        sumInp+=inputs.sum(dim=0)\n",
    "        totObs+=inputs.size(0)\n",
    "        del inputs  # ✅ Libère la mémoire\n",
    "        xm.mark_step()  # ✅ Assure la libération sur TPU\n",
    "        \n",
    "    totMean=sumInp/totObs\n",
    "    \n",
    "    for i, data in enumerate(dataloader):\n",
    "        inputs =data[0].to(device)\n",
    "        sumSqDiff+=((inputs-totMean)**2).sum(dim=0)\n",
    "\n",
    "        del inputs  # ✅ Libère la mémoire\n",
    "        xm.mark_step()  # ✅ Assure la libération sur TPU\n",
    "        \n",
    "    totVar=sumSqDiff/totObs\n",
    "    totStd=torch.sqrt(totVar+1e-8)\n",
    "    return totMean, totStd\n",
    "\n",
    "\n",
    "def training(model, device, train_dl, num_epochs):\n",
    "    #store_results\n",
    "    accuracies=[]\n",
    "    losses=[]\n",
    "    #Put the model in training mode \n",
    "    model.train()\n",
    "    # Loss Function, Optimizer and Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "    trainMean, trainStd=normalize_ds(train_dl, device)\n",
    "    \n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "        \n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        \n",
    "            # Normalize the inputs\n",
    "            inputs = (inputs - trainMean.view(1,*trainMean.shape)) / trainStd.view(1,*trainStd.shape)\n",
    "        \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            xm.optimizer_step(optimizer, barrier=True)\n",
    "            scheduler.step()\n",
    "        \n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "        \n",
    "            #if i % 10 == 0:    # print every 10 mini-batches\n",
    "            #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "            \n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/total_prediction\n",
    "        accuracies.append(acc)\n",
    "        losses.append(avg_loss)\n",
    "        xm.master_print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
    "    \n",
    "    xm.master_print('Finished Training')\n",
    "    return accuracies, losses, trainMean, trainStd         \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17671bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:44.871831Z",
     "iopub.status.busy": "2025-02-26T09:46:44.871544Z",
     "iopub.status.idle": "2025-02-26T09:46:47.809084Z",
     "shell.execute_reply": "2025-02-26T09:46:47.807671Z"
    },
    "papermill": {
     "duration": 2.951771,
     "end_time": "2025-02-26T09:46:47.811335",
     "exception": false,
     "start_time": "2025-02-26T09:46:44.859564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ----------------------------\n",
    "# Inference\n",
    "# ----------------------------\n",
    "def inference (model, test_dl, device, trainMean, trainStd ):\n",
    "    model.eval() #Put the model in eval/testing mode\n",
    "    allPreds=[]\n",
    "    allLabels=[]\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "    \n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in test_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # Normalize the inputs\n",
    "            inputs = (inputs -  trainMean.view(1,*trainMean.shape)) / trainStd.view(1,*trainStd.shape)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "            allPreds.append(prediction.cpu().numpy())\n",
    "            allLabels.append(labels.cpu().numpy())\n",
    "\n",
    "    #Concatenate all results over the entire test set\n",
    "    allPreds = np.concatenate(allPreds)\n",
    "    allLabels = np.concatenate(allLabels)\n",
    "    \n",
    "    acc = correct_prediction/total_prediction\n",
    "    xm.master_print(f'On inference : Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "\n",
    "    # Compute Confusion Matrix\n",
    "    confMatrix = confusion_matrix(allLabels, allPreds)\n",
    "\n",
    "\n",
    "     # Comput Classification Report (precision, recall, f1-score, support)\n",
    "    classReport = classification_report(allLabels, allPreds,output_dict=True, digits=4, zero_division=0)\n",
    "\n",
    "\n",
    "    return confMatrix, classReport\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdd76e50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T09:46:47.831817Z",
     "iopub.status.busy": "2025-02-26T09:46:47.831336Z",
     "iopub.status.idle": "2025-02-26T12:10:41.619413Z",
     "shell.execute_reply": "2025-02-26T12:10:41.617666Z"
    },
    "papermill": {
     "duration": 8633.800224,
     "end_time": "2025-02-26T12:10:41.620844",
     "exception": false,
     "start_time": "2025-02-26T09:46:47.820620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1740563209.696227      74 common_lib.cc:621] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: === \n",
      "learning/45eac/tfrc/runtime/common_lib.cc:239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.08, Accuracy: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.61, Accuracy: 0.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.33, Accuracy: 0.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 1.05, Accuracy: 0.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.88, Accuracy: 0.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.73, Accuracy: 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.61, Accuracy: 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.50, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.39, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.30, Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.24, Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.20, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.17, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.16, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.14, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.11, Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.10, Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.11, Accuracy: 0.98\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Fold 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On inference : Accuracy: 0.96, Total items: 367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.12, Accuracy: 0.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.62, Accuracy: 0.49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.31, Accuracy: 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 1.02, Accuracy: 0.65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.84, Accuracy: 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.71, Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.57, Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.46, Accuracy: 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.37, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.31, Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.26, Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.21, Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.19, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.15, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.16, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.14, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.13, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.12, Accuracy: 0.97\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Fold 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On inference : Accuracy: 0.98, Total items: 367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.09, Accuracy: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.60, Accuracy: 0.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.29, Accuracy: 0.57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 1.05, Accuracy: 0.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.84, Accuracy: 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.71, Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.57, Accuracy: 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.48, Accuracy: 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.40, Accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.31, Accuracy: 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.25, Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.22, Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.18, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.17, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.16, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.13, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.13, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.13, Accuracy: 0.97\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Fold 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On inference : Accuracy: 0.99, Total items: 367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.06, Accuracy: 0.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.64, Accuracy: 0.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.32, Accuracy: 0.56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 1.07, Accuracy: 0.63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.85, Accuracy: 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.73, Accuracy: 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.60, Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.45, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.35, Accuracy: 0.90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.28, Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.22, Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.21, Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.18, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.14, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.13, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.13, Accuracy: 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.11, Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.10, Accuracy: 0.98\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Fold 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On inference : Accuracy: 0.97, Total items: 367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.08, Accuracy: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 1.57, Accuracy: 0.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 1.26, Accuracy: 0.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Loss: 0.99, Accuracy: 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss: 0.79, Accuracy: 0.73\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Loss: 0.64, Accuracy: 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Loss: 0.47, Accuracy: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Loss: 0.36, Accuracy: 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Loss: 0.26, Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Loss: 0.21, Accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.17, Accuracy: 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Loss: 0.13, Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Loss: 0.12, Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Loss: 0.10, Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Loss: 0.09, Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Loss: 0.09, Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Loss: 0.08, Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Loss: 0.08, Accuracy: 0.99\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Fold 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On inference : Accuracy: 0.98, Total items: 367\n"
     ]
    }
   ],
   "source": [
    "mainDir='/kaggle/input/mynumpyfiles/NumpyDS'\n",
    "nbFold=5\n",
    "conf_matrix=[]\n",
    "report_dict={}\n",
    "for i in range(nbFold):\n",
    "    #myTrain contains the data to be fed to the DataDS class for batch processing later on\n",
    "    myTrain=myGlobalDs[(myGlobalDs['Fold']==i) & (myGlobalDs['Type']=='Train')].copy()\n",
    "    myTrain=myTrain.drop(columns=['Fold', 'Type', 'nb', 'condLabel'])\n",
    "    \n",
    "    # myDs is an instance of DataDS, constructor needs :\n",
    "    #         A dataframe with at least relative paths in a column 'FilePath' and a column 'LabelIDs'\n",
    "    #         An absolute path which is a level above the relative path mentioned in the dataframe \n",
    "    trainFoldi=DataDS(myTrain, mainDir)\n",
    "    train_dataloader = DataLoader(trainFoldi, batch_size=8, shuffle=True)\n",
    "    \n",
    "    #Do the same loading for the test set\n",
    "    myTest=myGlobalDs[(myGlobalDs['Fold']==i) & (myGlobalDs['Type']=='Test')].copy()\n",
    "    testFoldi=DataDS(myTest, mainDir)\n",
    "    test_dataloader = DataLoader(testFoldi, batch_size=8, shuffle=False)\n",
    "    \n",
    "    # Create the model and put it on the GPU if available\n",
    "    myModel = ToolClassifier()\n",
    "    #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #With TPU\n",
    "    device = xm.xla_device()\n",
    "    train_dataloader=MpDeviceLoader(train_dataloader, device)\n",
    "    test_dataloader=MpDeviceLoader(test_dataloader, device)\n",
    "    myModel = myModel.to(device)\n",
    "    # Check that it is on Cuda\n",
    "    next(myModel.parameters()).device\n",
    "  \n",
    "    num_epochs=18   # Exctracted by learning curve on Epochs\n",
    "    accuracies, losses, trainMean, trainStd=training(myModel, device, train_dataloader, num_epochs)\n",
    "    \n",
    "    # Run inference on trained model with the test set\n",
    "    print(f\"Results for Fold {i}\")\n",
    "    confMatrix, report=inference(myModel, test_dataloader,device, trainMean, trainStd)\n",
    "    conf_matrix.append(confMatrix)\n",
    "    report_df=pd.DataFrame(report).transpose()\n",
    "    report_dict[f\"Fold {i}\"]=report_df\n",
    "\n",
    "#PyTorch class weight APRES \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b107fe34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T12:10:41.650735Z",
     "iopub.status.busy": "2025-02-26T12:10:41.650478Z",
     "iopub.status.idle": "2025-02-26T12:10:41.655280Z",
     "shell.execute_reply": "2025-02-26T12:10:41.654123Z"
    },
    "papermill": {
     "duration": 0.021711,
     "end_time": "2025-02-26T12:10:41.656879",
     "exception": false,
     "start_time": "2025-02-26T12:10:41.635168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataDS\t DataLoader\t DataUtils\t Dataset\t F\t MpDeviceLoader\t ToolClassifier\t accuracies\t classification_report\t \n",
      "confMatrix\t conf_matrix\t confusion_matrix\t csv\t device\t dirname\t filenames\t i\t inference\t \n",
      "init\t losses\t mainDir\t math\t met\t myGlobalDs\t myMeta\t myModel\t myTest\t \n",
      "myTrain\t nbFold\t nn\t normalize_ds\t np\t num_epochs\t os\t pd\t pl\t \n",
      "plt\t random\t report\t report_df\t report_dict\t testFoldi\t test_dataloader\t test_utils\t torch\t \n",
      "torch_xla\t torchaudio\t trainFoldi\t trainMean\t trainStd\t train_dataloader\t training\t transforms\t warnings\t \n",
      "xm\t xmp\t xr\t xu\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53200462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T12:10:41.685886Z",
     "iopub.status.busy": "2025-02-26T12:10:41.685625Z",
     "iopub.status.idle": "2025-02-26T12:10:41.688789Z",
     "shell.execute_reply": "2025-02-26T12:10:41.688064Z"
    },
    "papermill": {
     "duration": 0.019971,
     "end_time": "2025-02-26T12:10:41.690546",
     "exception": false,
     "start_time": "2025-02-26T12:10:41.670575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#report_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef586de3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T12:10:41.719791Z",
     "iopub.status.busy": "2025-02-26T12:10:41.719574Z",
     "iopub.status.idle": "2025-02-26T12:10:41.731061Z",
     "shell.execute_reply": "2025-02-26T12:10:41.730326Z"
    },
    "papermill": {
     "duration": 0.028499,
     "end_time": "2025-02-26T12:10:41.732755",
     "exception": false,
     "start_time": "2025-02-26T12:10:41.704256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, matrix in enumerate(conf_matrix):\n",
    "    df = pd.DataFrame(matrix)\n",
    "    df.to_csv(f\"/kaggle/working/confusion_matrix_CNN_fold_{i+1}.csv\", index=False)\n",
    "del i, matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a97b540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T12:10:41.762060Z",
     "iopub.status.busy": "2025-02-26T12:10:41.761835Z",
     "iopub.status.idle": "2025-02-26T12:10:41.768745Z",
     "shell.execute_reply": "2025-02-26T12:10:41.767829Z"
    },
    "papermill": {
     "duration": 0.023554,
     "end_time": "2025-02-26T12:10:41.770424",
     "exception": false,
     "start_time": "2025-02-26T12:10:41.746870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, report in enumerate(report_dict):\n",
    "    report_dict[report].to_csv(f\"/kaggle/working/Reports_CNN_Fold_{i+1}.csv\", index=True)\n",
    "del i, report\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 6624622,
     "sourceId": 10691564,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8770.752336,
   "end_time": "2025-02-26T12:10:47.504131",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-26T09:44:36.751795",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
