{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import the list of csv files containing the measurements "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c28d6cf1e625e93"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import array\n",
    "import struct\n",
    "import csv  \n",
    "from tqdm import tqdm\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:17:20.685088900Z",
     "start_time": "2025-02-27T15:17:19.081207400Z"
    }
   },
   "id": "85caa03fc41b2118"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.2.post1\n",
      "0.5.0.post1\n",
      "3.0.1\n"
     ]
    }
   ],
   "source": [
    "import soxr\n",
    "import audioread\n",
    "print(librosa.__version__)\n",
    "print(soxr.__version__)\n",
    "print(audioread.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:17:20.708951Z",
     "start_time": "2025-02-27T15:17:20.688366800Z"
    }
   },
   "id": "7d1722109cc26968"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_085931.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090031.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090131.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090231.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090331.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090431.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090531.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090631.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090731.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090831.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_090931.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091031.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091131.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091231.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091331.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091431.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091531.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091631.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091731.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091831.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_091931.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092031.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092131.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092231.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092331.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092431.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092531.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092631.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092731.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_092932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_093932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_094932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_095932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_100932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_101932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_102932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_103932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_104932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105032.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105132.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105232.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105332.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105432.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105532.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105632.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105732.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105832.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_105932.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110033.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110133.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110233.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110333.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110433.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110533.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110633.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110733.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110833.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_110933.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111033.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111133.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111233.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111333.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111433.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111533.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111633.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111733.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111833.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_111933.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112033.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112133.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112233.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112333.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112433.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112533.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112633.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112733.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112833.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_112933.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113033.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113133.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113233.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113333.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113433.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113533.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113633.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113733.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113833.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_113933.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_114033.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_114133.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_114233.csv', 'F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_114333.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mypath='F:/Data_BachelorHES/1.raw_measurements/'\n",
    "onlyfiles = [join(mypath,f) for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(onlyfiles)\n",
    "del mypath"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:17:20.734803200Z",
     "start_time": "2025-02-27T15:17:20.697546300Z"
    }
   },
   "id": "c4947d86e11e76dc"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:/Data_BachelorHES/1.raw_measurements/PMPM_RAW_BIN_1m_20241116_114333.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "filename_Training = np.array(onlyfiles)\n",
    "print(filename_Training[-1])\n",
    "del onlyfiles"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:17:23.644091100Z",
     "start_time": "2025-02-27T15:17:23.549801500Z"
    }
   },
   "id": "6795bedd785b8bd6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Raw Data to CSV for each sensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "889363376310cdea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "ind=0\n",
    "destMeasurementsPath=\"F:/Data_BachelorHES/2.extracted_measurements/\"\n",
    "\n",
    "for file in filename_Training:\n",
    "    values = []\n",
    "    print('Reading file:',file)\n",
    "    \n",
    "    # Lire le fichier .csv qui contient le flux de bytes\n",
    "    with open(file, 'rb') as f:\n",
    "        byte_stream = f.read()  # Lire tout le fichier comme un flux de bytes\n",
    "    num_values = len(byte_stream) // 2  # Calcul du nombre d'entiers (INT16)\n",
    "\n",
    "\n",
    "    for i in range(num_values):\n",
    "        two_bytes = byte_stream[i*2:(i*2)+2] #gather one byte and the next to be reconstructed as int16\n",
    "        value = struct.unpack('<h', two_bytes)[0]  # '<h' pour 2 bytes en short int\n",
    "        values.append(value) #values is a list of int16\n",
    "        \n",
    "    npValues=np.array(values, dtype=np.int16) #transform the list into a numpy array of np.int16 numbers\n",
    "    if ind==0:\n",
    "        sound_size=50 #size of the buffer of EL3632 (-1) Channel 1\n",
    "        accelX_size=50#size of the buffer of EL3632 (-1) Channel 2\n",
    "        accelY_size=50#size of the buffer of EL3632 (-2) Channel 1\n",
    "        accelZ_size=50#size of the buffer of EL3632 (-2) Channel 2\n",
    "        slice_size=sound_size+accelX_size+accelY_size+accelZ_size\n",
    "        num_slice = len(npValues)//slice_size # Number of slices of 200 samples\n",
    "        #Extract corresponding indices for each sensor for one file (will be repeated for each file) \n",
    "        sound_indices=np.concatenate([np.arange(i*slice_size, i*slice_size+sound_size) for i in range(num_slice)])\n",
    "        accelX_indices=np.concatenate([np.arange(i*slice_size+sound_size, i*slice_size+sound_size+accelX_size) for i in range(num_slice)])\n",
    "        accelY_indices=np.concatenate([np.arange(i*slice_size+sound_size+accelX_size, i*slice_size+sound_size+accelX_size+accelY_size) for i in range(num_slice)])\n",
    "        accelZ_indices=np.concatenate([np.arange(i*slice_size+sound_size+accelX_size+accelY_size, i*slice_size+slice_size) for i in range(num_slice)])\n",
    "        del sound_size, accelY_size, accelX_size, accelZ_size, slice_size, num_slice\n",
    "    \n",
    "    #Split each file into 4 csv files for each sensor    \n",
    "    soundValues=npValues[sound_indices]\n",
    "    accelXValues=npValues[accelX_indices]\n",
    "    accelYValues=npValues[accelY_indices]\n",
    "    accelZValues=npValues[accelZ_indices]\n",
    "    \n",
    "    #Send to a dictionnary -> pandasDataframe \n",
    "    myMeasures ={}\n",
    "    myMeasures[\"Sound\"]=soundValues.astype(np.int16, casting='safe')\n",
    "    myMeasures[\"Accel X\"]=accelXValues.astype(np.int16, casting='safe')\n",
    "    myMeasures[\"Accel Y\"]=accelYValues.astype(np.int16, casting='safe')\n",
    "    myMeasures[\"Accel Z\"]=accelZValues.astype(np.int16, casting='safe')\n",
    "    myDfMeas=pd.DataFrame(myMeasures)\n",
    "    \n",
    "    #Write to csv file for each sensor. mode='a' indicate that we append to the file\n",
    "    myDfMeas.to_csv(join(destMeasurementsPath,\"sound.csv\"), columns=[\"Sound\"], index=False, mode='a', header=False)\n",
    "    myDfMeas.to_csv(join(destMeasurementsPath,\"accelX.csv\"), columns=[\"Accel X\"], index=False, mode='a', header=False)\n",
    "    myDfMeas.to_csv(join(destMeasurementsPath,\"accelY.csv\"), columns=[\"Accel Y\"], index=False, mode='a', header=False)\n",
    "    myDfMeas.to_csv(join(destMeasurementsPath,\"acceZX.csv\"), columns=[\"Accel Z\"], index=False, mode='a', header=False)\n",
    "    ind+=1\n",
    "    print(\"Data from file {} written to csv\".format(file))\n",
    "    del soundValues, accelXValues, accelYValues, accelZValues, myMeasures, myDfMeas, byte_stream, value, two_bytes, npValues\n",
    "del num_values, values, sound_indices, accelX_indices, accelY_indices, accelZ_indices, ind, file, i\n",
    "    \n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "496340291187d7c5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export sound data to a wavefile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "810c66c10794852c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(495000000, 1)\n"
     ]
    }
   ],
   "source": [
    "sound = pd.read_csv('F:/Data_BachelorHES/2.extracted_measurements/sound.csv', header=None, names=['values'])\n",
    "sound.head()\n",
    "print(sound.shape)\n",
    "\n",
    "#store the values from the pandas dataframe into a python array \n",
    "data_array = array.array('h', sound.values.flatten().astype(int))  # 'h' pour int16 (2 octets par valeur)\n",
    "del sound"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:20:24.351792900Z",
     "start_time": "2025-02-27T15:17:35.437487500Z"
    }
   },
   "id": "92ac25b6f8ee4420"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3098 -32768\n"
     ]
    }
   ],
   "source": [
    "print(np.max(data_array), np.min(data_array))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:20:24.548477900Z",
     "start_time": "2025-02-27T15:20:24.355645300Z"
    }
   },
   "id": "a513d2b89b4c1671"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of numpy array: (495000000,)\n",
      "Before normalization, Max value of numpy array: 3098.0 and Min value of numpy array: -32768.0\n"
     ]
    }
   ],
   "source": [
    "# Convert python array into numpy array in float as to normalize the values between -1 and 1\n",
    "data_array_np = np.array(data_array, dtype=np.float32)\n",
    "print(\"Shape of numpy array:\", data_array_np.shape)\n",
    "print(f\"Before normalization, Max value of numpy array: {np.max(data_array_np)} and Min value of numpy array: {np.min(data_array_np)}\")\n",
    "del data_array\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:20:26.305088200Z",
     "start_time": "2025-02-27T15:20:24.546550Z"
    }
   },
   "id": "c411d189962dd8"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "data_array_np = data_array_np/32768.0  # Normalization of values between -1 and 1\n",
    "# We will resample the original sound data to 48kHz to match the audio bitrate from the video\n",
    "fs_original = 50000  # 50 kHz\n",
    "fs_target = 48000    # 48 kHz\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:20:27.602024900Z",
     "start_time": "2025-02-27T15:20:26.306897200Z"
    }
   },
   "id": "de5d6fc710f7588e"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization and resampling, Max value of numpy array:0.094422347843647 and Min value of numpy array: -1.0035430192947388\n"
     ]
    }
   ],
   "source": [
    "# Resampling with librosa\n",
    "resampled_data = librosa.resample(data_array_np, orig_sr=fs_original, target_sr=fs_target)\n",
    "print(f\"After normalization and resampling, Max value of numpy array:{np.max(resampled_data)} and Min value of numpy array: {np.min(resampled_data)}\")\n",
    "# resampling might affect original normalization, so we need to re-normalize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:29:54.549373100Z",
     "start_time": "2025-02-27T15:29:01.420743600Z"
    }
   },
   "id": "fb5394260c88ea3d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization of the resampled array, Max value of numpy array: 0.09408898651599884 and Min value of numpy array: -1.0\n"
     ]
    }
   ],
   "source": [
    "# Find max and min values\n",
    "max_val = resampled_data.max()\n",
    "min_val = resampled_data.min()\n",
    "# Re-normalize between -1 and 1 and store into resampled_array\n",
    "resampled_array = resampled_data / max(abs(max_val), abs(min_val))\n",
    "print(f\"After normalization of the resampled array, Max value of numpy array: {np.max(resampled_array)} and Min value of numpy array: {np.min(resampled_array)}\")\n",
    "del max_val, min_val"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:31:33.526796200Z",
     "start_time": "2025-02-27T15:31:31.257693500Z"
    }
   },
   "id": "81a0db5cc75c1968"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\n",
    "#Export resampled array into a wav file with 16 bits PCM encoding for Audacity\n",
    "sf.write('F:/Data_BachelorHES/4.audio_synchronization/resampled_audio_exp_sf.wav', resampled_array, fs_target, subtype='PCM_16')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:32:56.688917200Z",
     "start_time": "2025-02-27T15:32:22.714697700Z"
    }
   },
   "id": "98b5bd271e66277f"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Export rsampled_array to another .wav file after amplification\n",
    "gain_db = 20.0\n",
    "amplification_factor = 10 ** (gain_db / 20)\n",
    "\n",
    "# Apply amplification factor to the original data\n",
    "amplified_signal = resampled_array * amplification_factor\n",
    "\n",
    "# Normalize\n",
    "amplified_signal = np.clip(amplified_signal, -1.0, 1.0)\n",
    "\n",
    "#export\n",
    "sf.write('F:/Data_BachelorHES/4.audio_synchronization/resampled_audio_exp_sf_amplified.wav', resampled_array, fs_target, subtype='PCM_16')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-27T15:33:32.651095100Z",
     "start_time": "2025-02-27T15:32:56.697915800Z"
    }
   },
   "id": "fb4c53f32f404296"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2ba4dfc9ebfe3b52"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Décalage trouvé avec Audacity\n",
    "Situé le deuxième clap à environ 36 secondes après le début de la vidéo depuis la vidéo. Sur audacity, le pic du clap se trouve à l'échantillon 1'751'944 => @ 48KHz => 36.499s\n",
    "Ce second clap est plus difficile à situer sur l'enregistrement du microphone. \n",
    "Pour réaliser une pré-synchronisation, on  utilisera une séquence de la machine particulièrement reconnaissable, une série de son \"haute\" fréquence audible à la fois dans l'enregistrement du microphone et dans l'enregistrement de la vidéo. Pour situer ces sons haute fréquences, on visualise les stream audio en spectrogramme dans Audacity. On regarde à quel échantillon approximatif ils commencent dans les deux streams. On calcule le décalage entre les deux streams et on l'applique à l'enregistrement de la vidéo pour synchroniser les deux streams. Cette pré-synchronisation nous donne un décalage de 14'874'177 échantillons (soit 5min 9s 879ms). A partir de là, on sait qu' à ~10'000 échantillons prés (~200ms), nos flux sont synchronisés. \n",
    "Après ce décalage, le second clap se trouve à l'échantillon 16'626'121 sur le son de la vidéo.\n",
    "On repasse ensuite sur la zone du second clap pour tenter d'entendre ce clap sur le son du microphone. Et heureusement on l'entend assez distinctement. Cependant le pic n'est pas aussi marqué que sur l'enregistrement du son de la vidéo. Il s'agit plutôt d'une vague aplatie avec un dizaine d'échantillons de largeur. On peut donc considérer que le clap se situe entre les échantillons 16'627'385 et 16'627'394. On peut donc considérer que le clap se situe au centre de cette vague, soit à l'échantillon 16'627'390. Ainsi le clap du microphone à 16'627'390 et celui de la vidéo à 16'626'121 sont décalés de 1'269 échantillons (soit 26ms).  Le décalage total se porte ainsi à 14'875'446 échantillons (soit 5min 9s 905ms).\n",
    "\n",
    "Il est intéressant de noter que le pic du clap est aussi décalé entre les deux flux \"stéréo\" de la vidéo d'environ 7 échantillons. Ce décalage est dû à plusieurs paramêtres: placement des deux micro du téléphone, distance entre le clap et le téléphone, traitement interne du signal par le téléphone (ADC, DSP etc..) etc..  Ainsi on peut déterminer que notre synchronisation est correct avec une tolérance de +/- 100 échantillons. Car le micro de la machine et de la caméra ne sont pas situés au même endroit et que le clap n'est pas un son ponctuel mais un son d'une certaine durée.  \n",
    "\n",
    "Pour la suite de l'analyse nous jetterons ainsi les échantillons 0 à 14'875'446 de l'enregistrement du son du microphone.\n",
    "Cependant comme nous avons travaillé avec Audacity sur un projet avec un tx d'échantillonnage à 48kHz, alors que nous avons des valeurs sur 50kHz (14'875'446*50/48), nous devons exclure les échantillons 0 à 15'495'256 pour le microphone et les 3 axes de l'accéléromètre.\n",
    "\n",
    "\n",
    "Ensuite, lors de l'OCR nous avons dû exclure les frame 0 à 9964 (soit les 9965 premières frames) et que nous avons un temps en millisecondes jusqu'à la frame rate 9965 de 332'245.6 ms, nous devons également exclure les 15'947'789 échantillons suivants (à 48kHz) de l'enregistrement du microphone et du son de la vidéo. Ainsi il faut exclure les enregistrements 0 à 30'823'235 pour le microphone et les 3 axes de l'accéléromètre, ce qui ramené à la fréquence d'échantillonnage originale de 50kHz, correspond à l'échantillon 32'107'536.\n",
    "\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd1722411a63ee71"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Map the frames to the corresponding samples for microphone and accelerometer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc69e292ba876254"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class FrameInfo:\n",
    "    def __init__(self, frame_number, time_in_milliseconds, measCount, measLowIndex, HighIndex):\n",
    "        self.frame_number = frame_number\n",
    "        self.time_in_milliseconds = time_in_milliseconds\n",
    "        self.measCount=measCount\n",
    "        self.measLowIndex=measLowIndex\n",
    "        self.HighIndex=HighIndex\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Frame {self.frame_number} at {self.time_in_milliseconds} ms with {self.measCount} measurements at index {self.measLowIndex} to {self.HighIndex}\"\n",
    "    \n",
    "    def getNbMeas(self):\n",
    "        return self.measCount\n",
    "    def getMeasIndex(self):\n",
    "        return (self.measLowIndex, self.HighIndex)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T17:58:54.962998100Z",
     "start_time": "2025-03-03T17:58:54.938388900Z"
    }
   },
   "id": "70eaa8fbcb8f27df"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import cv2\n",
    "video_path = 'F:/Data_BachelorHES/3.Video_CNC/Video_CNC.mp4'\n",
    "cap = cv2.VideoCapture(video_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T17:58:55.532892100Z",
     "start_time": "2025-03-03T17:58:54.972358500Z"
    }
   },
   "id": "b40f6c7a46a2fcf9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of stream ... Exiting ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frameData=[]\n",
    "\n",
    "count=9965\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
    "cap.read()\n",
    "while cap.isOpened():\n",
    "        \n",
    "    actualTime=cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, count+5)\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        frameData.append(FrameInfo(count, actualTime, 0, highIndex, highIndex))\n",
    "        print(\"End of stream ... Exiting ...\")\n",
    "        break\n",
    "    \n",
    "   \n",
    "    nextTime=cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "    lowIndex=15495256 + int(actualTime*50)\n",
    "    highIndex=15495256 + int(nextTime*50)\n",
    "    totMeas=highIndex-lowIndex\n",
    "    frameData.append(FrameInfo(count, actualTime, totMeas, lowIndex, highIndex))\n",
    "    count+=5\n",
    "del totMeas, ret, highIndex, lowIndex, frame, count, actualTime, nextTime\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-03T22:10:46.144565100Z",
     "start_time": "2025-03-03T17:59:31.704648600Z"
    }
   },
   "id": "7d6e003dca88c98"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Frame 285545 at 9520340.066666668 ms with 0 measurements at index 491512259 to 491512259"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frameData[-1].frame_number"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:27:35.013246800Z",
     "start_time": "2025-03-04T07:27:34.940698900Z"
    }
   },
   "id": "d818d0ef03d3b9ba"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 285545 at 9520340.066666668 ms with 0 measurements at index 491512259 to 491512259\n"
     ]
    }
   ],
   "source": [
    "print(frameData[-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:31:50.549113Z",
     "start_time": "2025-03-04T07:31:50.418907300Z"
    }
   },
   "id": "a8faa64a1ce8767c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 285545 at 9520340.066666668 ms with 1667 measurements at index 491512259 to 491513926\n"
     ]
    }
   ],
   "source": [
    "#Add infos for the last frame which last 1 frame (that is 1/fps)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "duration=1.0/fps\n",
    "totMeasurements=int(duration*50000)\n",
    "lowIndex=15495256 + int(frameData[-1].time_in_milliseconds*50)\n",
    "highIndex=lowIndex+totMeasurements\n",
    "frameData[-1].measCount=totMeasurements\n",
    "frameData[-1].measLowIndex=lowIndex\n",
    "frameData[-1].HighIndex=highIndex\n",
    "print(frameData[-1])\n",
    "del highIndex, lowIndex, totMeasurements, duration, fps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:36:54.134257Z",
     "start_time": "2025-03-04T07:36:54.075709700Z"
    }
   },
   "id": "72f52421ec594a0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e859452087b1db71"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
